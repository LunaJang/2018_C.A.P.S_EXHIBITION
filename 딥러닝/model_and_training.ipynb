{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch 라이브러리 임포트\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from os import walk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# scikit-learn 라이브러리 임포트\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Place all the npy quickdraw files here:\n",
    "mypath = \"data/\"\n",
    "txt_name_list = []\n",
    "for (dirpath, dirnames, filenames) in walk(mypath):\n",
    "    if filenames != 'Aa':       ##Ugh mac junk\n",
    "        txt_name_list.extend(filenames)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "xtotal = []\n",
    "ytotal = []\n",
    "slice_train = int(80000/len(txt_name_list))  ###Setting value to be 80000 for the final dataset\n",
    "i = 0\n",
    "seed = np.random.randint(1, 10e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creates test/train split with quickdraw data\n",
    "for txt_name in txt_name_list:\n",
    "    txt_path = mypath + txt_name\n",
    "    x = np.load(txt_path)\n",
    "    x = x.astype('float32') / 255.    ##scale images\n",
    "    y = [i] * len(x)  \n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(x)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(y)\n",
    "    x = x[:slice_train]\n",
    "    y = y[:slice_train]\n",
    "    if i != 0: \n",
    "        xtotal = np.concatenate((x,xtotal), axis=0)\n",
    "        ytotal = np.concatenate((y,ytotal), axis=0)\n",
    "    else:\n",
    "        xtotal = x\n",
    "        ytotal = y\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 건수\n",
    "train_size = 5000\n",
    "# 테스트 데이터 건수\n",
    "test_size = 500\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "    xtotal, ytotal, train_size=train_size,test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이가 784인 1차원 배열을 28*28 크기의 2차원 배열로 만듬\n",
    "train_X = train_X.reshape((len(train_X), 1, 28, 28))\n",
    "test_X = test_X.reshape((len(test_X), 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 텐서 변환\n",
    "train_X = torch.from_numpy(train_X).float()\n",
    "train_Y = torch.from_numpy(train_Y).long()\n",
    "\n",
    "# 테스트 데이터 텐서 변환\n",
    "test_X = torch.from_numpy(test_X).float()\n",
    "test_Y = torch.from_numpy(test_Y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명변수와 목적변수 텐서를 합침\n",
    "train = TensorDataset(train_X, train_Y)\n",
    "\n",
    "# 미니배치 분할\n",
    "train_loader = DataLoader(train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 구성\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 합성곱층\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # 입력 채널 수, 출력 채널 수, 필터 크기\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # 전결합층\n",
    "        self.fc1 = nn.Linear(256, 64) # 256 = (((28-5+1)/2 )-5+1)/2 * (((28-5+1)/2 )-5+1)/2 * 16\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 풀링층\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2) # 풀링 영역 크기\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 256)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)\n",
    "    \n",
    "# 인스턴스 생성\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\pytlesson\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 tensor(3.3264)\n",
      "200 tensor(2.0723)\n",
      "300 tensor(1.3053)\n",
      "400 tensor(0.7121)\n",
      "500 tensor(0.3301)\n",
      "600 tensor(0.2056)\n",
      "700 tensor(0.0933)\n",
      "800 tensor(0.0584)\n",
      "900 tensor(0.0442)\n",
      "1000 tensor(0.0320)\n"
     ]
    }
   ],
   "source": [
    "# 오차함수 객체\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화를 담당할 객체\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 학습 시작\n",
    "for epoch in range(1000):\n",
    "    total_loss = 0\n",
    "    # 분할해 둔 데이터를 꺼내옴\n",
    "    for train_x, train_y in train_loader:\n",
    "        # 계산 그래프 구성\n",
    "        # 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 순전파 계산\n",
    "        output = model(train_x)\n",
    "        # 오차계산\n",
    "        loss = criterion(output, train_y)\n",
    "        # 역전파 계산\n",
    "        loss.backward()\n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.item()\n",
    "    # 100회 반복마다 누적 오차 출력\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 그래프 구성\n",
    "test_x, test_y = Variable(test_X), Variable(test_Y)\n",
    "# 출력이 0 혹은 1이 되게 함\n",
    "result = torch.max(model(test_x).data, 1)[1]\n",
    "# 모형의 정확도 측정\n",
    "accuracy = sum(test_y.data.numpy() == result.numpy()) / len(test_y.data.numpy())\n",
    "\n",
    "# 모형의 정확도 출력\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "#example하나 선택\n",
    "ex = xtotal[4558]\n",
    "ex1 = ex.reshape(28,28)\n",
    "plt.imshow(ex1)\n",
    "plt.show()\n",
    "\n",
    "ex_X = ex.reshape(1,1,28, 28)\n",
    "ex_X = torch.from_numpy(ex_X).float()\n",
    "print(ex_X.shape)\n",
    "\n",
    "# 출력이 0 혹은 1이 되게 함\n",
    "result = torch.max(model(ex_X).data, 1)[1]\n",
    "\n",
    "#result 출력\n",
    "print(result.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
